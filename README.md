ğŸ“˜ Rate of Penetration (ROP) Prediction â€” Machine Learning Case Study
Author: Aya Elsadek

ğŸ“Œ Overview
This project presents a complete machine learning workflow for predicting the Rate of Penetration (ROP) in drilling operations using real drilling log data. The notebook includes data preprocessing, feature engineering, model training, hyperparameter optimization, explainability using SHAP, and diagnostic evaluation.

The goal is to build an accurate and interpretable model that captures the nonlinear behavior of drilling parameters and their interactions.

ğŸ“‚ Project Structure
ÙƒØªØ§Ø¨Ø© ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø¨Ø±Ù…Ø¬ÙŠØ©
â”œâ”€â”€ models/

â”‚   â”œâ”€â”€ final_rop_model.pkl

â”‚   â”œâ”€â”€ best_rf.joblib

â”‚   â”œâ”€â”€ scaler+poly.pkl

â”‚   â”œâ”€â”€ features.pkl

â”‚   â””â”€â”€ comparison_table_after_fixes.csv

â”œâ”€â”€ notebook.ipynb

â”œâ”€â”€ README.md

â””â”€â”€ data/ (not included)

ğŸ› ï¸ Technologies Used
Python (Pandas, NumPy)

Scikitâ€‘learn

XGBoost

SHAP

Matplotlib / Seaborn

Joblib

ğŸ“Š Dataset
The dataset contains 151 samples with the following drilling parameters:

Feature	Description
Depth	Measured depth
WOB	Weight on bit
SURF_RPM	Surface RPM
PHIF	Porosity
VSH	Shale volume
SW	Water saturation
KLOGH	Permeability log
ROP_AVG	Target variable

ğŸ”§ Data Preprocessing
The notebook performs several preprocessing steps:

âœ… Outlier Handling
IQR-based winsorization applied to all numeric features.

âœ… Feature Engineering

Includes both physical and statistical features:

SE (Specific Energy)

MSE (Mechanical Specific Energy)

EFF (Drilling Efficiency)

HHP_est (Hydraulic Horsepower estimate)

Log transform of permeability

Interaction terms (e.g., WOB Ã— RPM)

Rate-of-change features (first differences)

Rolling window features (MA3)

âœ… Scaling
StandardScaler

RobustScaler

PolynomialFeatures (degree = 2)

ğŸ¤– Models Trained

Several baseline models were trained:

Linear Regression

Ridge Regression

Lasso Regression

Random Forest

XGBoost

Both baseline and tuned versions were evaluated.

ğŸ† Model Performance
The best-performing model was:

âœ… XGBoost (baseline)
RMSE: 0.000871

RÂ²: 0.5825

A comparison table is saved in: models/comparison_table_after_fixes.csv

ğŸ” Model Explainability (SHAP)
SHAP was used to interpret the XGBoost model:

âœ… Global Insights
EFF and EFFÂ² strongly increase ROP

WOB and WOBÃ—RPM interactions reduce ROP

Only a small subset of polynomial features significantly influence predictions

âœ… Local Explanation
Waterfall and force plots show how individual features push predictions up or down.

âœ… Error Analysis
Two diagnostic plots were generated:

1. Predicted vs Actual ROP
Shows strong positive correlation and good model fit.

2. Residuals vs Depth
Residuals are randomly scattered around zero â†’ no depthâ€‘related bias.

ğŸ’¾ Saved Artifacts
The following files are saved for deployment or reuse:

final_rop_model.pkl â€” final XGBoost model

scaler+poly.pkl â€” preprocessing pipeline

features.pkl â€” feature list

best_rf.joblib â€” tuned Random Forest

comparison_table_after_fixes.csv â€” model comparison

ğŸš€ How to Run
Install dependencies:

bash
pip install -r requirements.txt
Load the model:

python
import joblib
model = joblib.load("models/final_rop_model.pkl")
Prepare input features and predict:

python
y_pred = model.predict(X_processed)

ğŸ“Œ Conclusion
This case study demonstrates a full ML pipeline for drilling ROP prediction, including:

Advanced feature engineering

Polynomial expansion

Model tuning

Explainability with SHAP

Diagnostic evaluation

The workflow is reproducible, interpretable, and ready for deployment.
